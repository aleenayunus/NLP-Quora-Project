{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model with Supervised Word Embeddings\n",
    "No pretrained embeddings were used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"pad\"}\n",
    "        self.n_words = 3  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.lower().split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "\n",
    "\n",
    "#returns object which has word2index mapping, index2word, vocalbulary size and vocabulary\n",
    "def get_question_metadata(question_list, reverse=False):\n",
    "    question_repo = Lang()\n",
    "    print(\"Read %s questions \" % len(question_list))\n",
    "    print(\"Counting words...\")\n",
    "    for question in question_list:\n",
    "        question_repo.addSentence(question)\n",
    "\n",
    "    print(\"Counted words:\")\n",
    "    print(question_repo.n_words)\n",
    "\n",
    "    return question_repo\n",
    "\n",
    "#make all the input text of the same size as size max_length input senetnce, padding with word \"PAD\"(zero padding)\n",
    "def make_input(sentence):\n",
    "    sent_len = len(sentence.split(' '))\n",
    "    if sent_len < MAX_LEN:\n",
    "        padded_sentence = sentence + (MAX_LEN - len(sentence.split(' '))) * \" PAD\"\n",
    "    else:\n",
    "        padded_sentence = sentence\n",
    "\n",
    "    return padded_sentence,sent_len\n",
    "\n",
    "#\n",
    "# def question_index_vector(question):\n",
    "#     input_question = indexesFromSentence(processed_input, question)\n",
    "#     return (input_question)\n",
    "\n",
    "#function to return batch of data\n",
    "def get_sentence_batch(batch_size,data_x,data_y,data_seqlens,input_metadata):\n",
    "    \n",
    "    #shuffling and creating training batch data of batch_size\n",
    "    instance_indices = list(range(len(data_x)))\n",
    "    np.random.shuffle(instance_indices)\n",
    "    batch = instance_indices[:batch_size]\n",
    "    \n",
    "    #converting sentence to index vector using word2index dictionary\n",
    "    x = [[input_metadata.word2index[word] for word in data_x[i].lower().split(' ')]for i in batch]\n",
    "    y = [data_y[i] for i in batch]\n",
    "    seqlens = [data_seqlens[i] for i in batch]\n",
    "    return x,y,seqlens\n",
    "\n",
    "def get_test_batch(batch_size,data_x, data_seqlens, input_metadata):\n",
    "    \n",
    "    #shuffling and creating training batch data of batch_size\n",
    "    instance_indices = list(range(len(data_x)))\n",
    "    np.random.shuffle(instance_indices)\n",
    "    batch = instance_indices[:batch_size]\n",
    "    \n",
    "    #converting sentence to index vector using word2index dictionary\n",
    "    x = [[input_metadata.word2index[word] for word in data_x[i].lower().split(' ')]for i in batch]\n",
    "    seqlens = [data_seqlens[i] for i in batch]\n",
    "    return x, seqlens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#loading data\n",
    "train_data = pd.read_csv(\"./data/train.csv\")\n",
    "test_data = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#extracting data required for training\n",
    "X_train = train_data[\"question_text\"]\n",
    "Y_train = train_data[\"target\"]\n",
    "\n",
    "X_test = test_data[\"question_text\"]\n",
    "# Y_test = test_data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing maximum length of question available in train.csv\n",
    "MAX_LEN = X_train.map(lambda x: len(x.split(' '))).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 128;embedding_dimension = 64;num_classes = 2\n",
    "hidden_layer_size = 32;time_steps = 122; element_size =1\n",
    "\n",
    "\n",
    "test_seqlens = []\n",
    "train_seqlens = []\n",
    "new_x_train = []\n",
    "new_y_train = []\n",
    "new_x_test = []\n",
    "# new_y_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1306122 questions \n",
      "Counting words...\n",
      "Counted words:\n",
      "450693\n",
      "Read 56370 questions \n",
      "Counting words...\n",
      "Counted words:\n",
      "64222\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "question_metadata = get_question_metadata(X_train)\n",
    "question_metadata_test = get_question_metadata(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#representing output in the form of one-hot format\n",
    "for i in range(len(Y_train)):\n",
    "    label = Y_train[i]\n",
    "    one_hot_encoding = [0]*2\n",
    "    one_hot_encoding[label] = 1\n",
    "    new_y_train.append(one_hot_encoding)\n",
    "\n",
    "for ques in X_train:\n",
    "    padded_sentence, sent_len = make_input(ques)\n",
    "    new_x_train.append(padded_sentence)\n",
    "    train_seqlens.append(sent_len)\n",
    "    \n",
    "# for i in range(len(Y_test)):\n",
    "#     label = Y_test[i]\n",
    "#     one_hot_encoding = [0]*2\n",
    "#     one_hot_encoding[label] = 1\n",
    "#     new_y_test.append(one_hot_encoding)\n",
    "#\n",
    "for ques in X_test:\n",
    "    padded_sentence, sent_len = make_input(ques)\n",
    "    new_x_test.append(padded_sentence)\n",
    "    test_seqlens.append(sent_len)\n",
    "\n",
    "\n",
    "# question_vectors = []\n",
    "# for question in X_train:\n",
    "#     question_vectors.append(indexesFromSentence(processed_input,question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating placeholders for data\n",
    "_inputs = tf.placeholder(tf.int32,shape=[None, time_steps], name=\"inputs\" )\n",
    "_labels = tf.placeholder(tf.float32, shape=[batch_size, num_classes], name=\"labels\" )\n",
    "\n",
    "#seqlens for dynamic calculations\n",
    "_seqlens = tf.placeholder(tf.int32, shape=[None], name=\"seqs\" )\n",
    "_inputs_test = tf.placeholder(tf.int32,shape=[None, time_steps], name=\"inputs_test\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aleena/nlp/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-10-2f511644e04c>:10: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-10-2f511644e04c>:13: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/aleena/nlp/venv/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#to obtain word's vector, tf.nn.embedding_lookup is used\n",
    "with tf.name_scope(\"embeddings\"):\n",
    "    embeddings = tf.Variable(tf.random_uniform([question_metadata.n_words,embedding_dimension],\n",
    "                                               -1.0,1.0,name='embedding'))\n",
    "    embed = tf.nn.embedding_lookup(embeddings,_inputs)\n",
    "\n",
    "with tf.variable_scope(\"lstm\"):\n",
    "    \n",
    "    lstm_cell = tf.nn.rnn_cell.LSTMCell(hidden_layer_size,forget_bias=1.0)\n",
    "    \n",
    "    #resolving the issue of adding noise as the form \"PAD\", by passing actual sequence length to tf.nn.dynamic_rnn() \n",
    "    output, states = tf.nn.dynamic_rnn(lstm_cell, embed, sequence_length = _seqlens,dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'linear_layer': tf.Variable(tf.truncated_normal([hidden_layer_size,num_classes],mean=0,stddev=.01))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'linear_layer': tf.Variable(tf.truncated_normal([num_classes],mean=0,stddev=.01))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-4099f12cbd63>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Extract the last relevant output and use in a linear  layer\n",
    "\n",
    "final_output = tf.matmul(states[1],weights['linear_layer'])+ biases['linear_layer']\n",
    "softmax = tf.nn.softmax_cross_entropy_with_logits(logits=final_output,labels=_labels)\n",
    "cross_entropy = tf.reduce_mean(softmax)\n",
    "\n",
    "train_step = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(_labels,1),tf.argmax(final_output,1))\n",
    "accuracy = (tf.reduce_mean(tf.cast(correct_prediction,tf.float32)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at 0: 19.53125\n",
      "Accuracy at 100: 93.75000\n",
      "Accuracy at 200: 94.53125\n",
      "Accuracy at 300: 95.31250\n",
      "Accuracy at 400: 93.75000\n",
      "Accuracy at 500: 92.18750\n",
      "Accuracy at 600: 94.53125\n",
      "Accuracy at 700: 94.53125\n",
      "Accuracy at 800: 92.96875\n",
      "Accuracy at 900: 93.75000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(1000):\n",
    "        x_batch, y_batch, seqlen_batch = get_sentence_batch(batch_size,new_x_train,new_y_train,train_seqlens,question_metadata)\n",
    "\n",
    "        sess.run(train_step,feed_dict={_inputs:x_batch,_labels:y_batch,_seqlens:seqlen_batch})\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            acc = sess.run(accuracy,feed_dict={_inputs:x_batch,_labels:y_batch,_seqlens:seqlen_batch})\n",
    "            print(\"Accuracy at %d: %.5f\" % (step,acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
