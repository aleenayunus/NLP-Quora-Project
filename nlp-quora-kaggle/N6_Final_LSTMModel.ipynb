{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Integrated Notebook\n",
    "This notebok combines all the steps performed in the previous notebooks in order to train the model and make predicitions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from N1_Downsampling.ipynb\n",
      "importing Jupyter notebook from N2_Preprocessing_FeatureExtraction.ipynb\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 161620 entries, 0 to 161619\n",
      "Data columns (total 3 columns):\n",
      "qid              161620 non-null object\n",
      "question_text    161620 non-null object\n",
      "target           161620 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.7+ MB\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161620/161620 [00:44<00:00, 3595.70it/s]\n",
      "100%|██████████| 161620/161620 [00:03<00:00, 42085.17it/s]\n",
      "100%|██████████| 161620/161620 [00:42<00:00, 3807.10it/s]\n",
      "100%|██████████| 161620/161620 [00:14<00:00, 11418.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import string\n",
    "import contractions\n",
    "import os\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.stem import  WordNetLemmatizer\n",
    "import inflect\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import collections\n",
    "import unicodedata\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import import_ipynb\n",
    "import N1_Downsampling as down\n",
    "import N2_Preprocessing_FeatureExtraction as pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading train_data, downsampling it and then loading test data\n",
    "train_data = pd.read_csv(\"./data/train.csv\")\n",
    "train_data = down.downsample(train_data)\n",
    "test_data = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting data required for training\n",
    "X_train = train_data[\"question_text\"]\n",
    "Y_train = train_data[\"target\"]\n",
    "X_test = test_data[\"question_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing maximum length of question available in train.csv\n",
    "MAX_LEN = X_train.map(lambda x: len(x.split(' '))).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting constants\n",
    "glove_word_embedding_path = \"./data/glove.840B.300d/glove.840B.300d.txt\"\n",
    "LOG_DIR = \"./checkpointing\"\n",
    "GLOVE_SIZE = 300\n",
    "embedding_size=300\n",
    "num_classes=2\n",
    "batch_size = 128; \n",
    "hidden_layer_size = 32;time_steps = 100; element_size =1\n",
    "\n",
    "\n",
    "test_seqlens = []\n",
    "train_seqlens = []\n",
    "new_x_train = []\n",
    "new_y_train = []\n",
    "new_x_test = []\n",
    "#new_y_test = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information extraction & manipulation\n",
    "Functions used to extract information from the data provided and then converting that data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"pad\"}\n",
    "        self.n_words = 3  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.lower().split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "\n",
    "#Uses the Lang class to return object which has word2index mapping, index2word, vocalbulary size and vocabulary\n",
    "def get_question_metadata(question_list, reverse=False):\n",
    "    question_repo = Lang()\n",
    "    print(\"Read %s question(s) \" % len(question_list))\n",
    "    for question in question_list:\n",
    "        question_repo.addSentence(question)\n",
    "    return question_repo\n",
    "\n",
    "\n",
    "#function to return batch of data by converting the words to index\n",
    "def get_sentence_batch(batch_size,data_x,data_y,data_seqlens,input_metadata):\n",
    "    \n",
    "    #shuffling and creating training batch data of batch_size\n",
    "    instance_indices = list(range(len(data_x)))\n",
    "    np.random.shuffle(instance_indices)\n",
    "    batch = instance_indices[:batch_size]\n",
    "    \n",
    "    #converting sentence to index vector using word2index dictionary\n",
    "    x = [[input_metadata.word2index[word] for word in data_x[i].lower().split(' ')]for i in batch]\n",
    "    y = [data_y[i] for i in batch]\n",
    "    seqlens = [data_seqlens[i] for i in batch]\n",
    "    return x,y,seqlens\n",
    "\n",
    "#function to return batch of test data in index form\n",
    "def get_test_batch(i, batch_size,data_x, data_seqlens, input_metadata):\n",
    "    \n",
    "    #creating test batch data of batch_size\n",
    "    instance_indices = list(range(len(data_x)))\n",
    "    batch = instance_indices[i:i+batch_size]\n",
    "    \n",
    "    #converting sentence to index vector using word2index dictionary\n",
    "    x = [[input_metadata.word2index[word] for word in data_x[i].lower().split(' ')]for i in batch]\n",
    "    \n",
    "    seqlens = [data_seqlens[i] for i in batch]\n",
    "    return x, seqlens\n",
    "\n",
    "#function to return the input question in index form\n",
    "def get_test(data_x, input_metadata):\n",
    "    x = []\n",
    "    for word in data_x.lower().split(' '):\n",
    "        if word == 'pad':\n",
    "            x.append(2)\n",
    "        else:\n",
    "            x.append(input_metadata.word2index[word]) \n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 161620 question(s) \n",
      "Read 56370 question(s) \n"
     ]
    }
   ],
   "source": [
    "#Retrieving metadata\n",
    "question_metadata = get_question_metadata(X_train)\n",
    "question_metadata_test = get_question_metadata(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding and Data Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#representing output in the form of one-hot format\n",
    "for i in range(len(Y_train)):\n",
    "    label = Y_train[i]\n",
    "    one_hot_encoding = [0]*2\n",
    "    one_hot_encoding[label] = 1\n",
    "    new_y_train.append(one_hot_encoding)\n",
    "\n",
    "#making train data of equal size by padding\n",
    "for ques in X_train:\n",
    "    padded_sentence, sent_len = pre.make_input(ques, time_steps)\n",
    "    new_x_train.append(padded_sentence)\n",
    "    train_seqlens.append(sent_len)\n",
    "\n",
    "#making test data of equal size by padding\n",
    "for ques in X_test:\n",
    "    padded_sentence, sent_len = pre.make_input(ques, time_steps)\n",
    "    new_x_test.append(padded_sentence)\n",
    "    test_seqlens.append(sent_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating placeholders for data\n",
    "_inputs = tf.placeholder(tf.int32,shape=[None, time_steps], name=\"inputs\")\n",
    "_labels = tf.placeholder(tf.float32, shape=[batch_size, num_classes], name=\"labels\")\n",
    "\n",
    "embedding_placeholder = tf.placeholder(tf.float32, [question_metadata.n_words,GLOVE_SIZE], name=\"emb\")\n",
    "\n",
    "#seqlens for dynamic calculations\n",
    "_seqlens = tf.placeholder(tf.int32, shape=[None], name=\"seqlen\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing train data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161620/161620 [00:37<00:00, 4263.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# \"\"\"Replace contractions in string of text\"\"\"\n",
    "contracted_input = X_train.progress_apply(lambda row:contractions.fix(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161620/161620 [00:03<00:00, 53844.31it/s]\n"
     ]
    }
   ],
   "source": [
    "#Text cleaning regarding punctuations, numerical values \n",
    "cleaned_text = contracted_input.progress_apply(lambda row:pre.clean_text(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161620/161620 [00:34<00:00, 4670.84it/s]\n"
     ]
    }
   ],
   "source": [
    "#tokenizing the words\n",
    "word_tokenised = cleaned_text.progress_apply(lambda text:nltk.word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161620/161620 [00:11<00:00, 13532.88it/s]\n"
     ]
    }
   ],
   "source": [
    "#lemmatizing the verbs\n",
    "lemmatized_words = word_tokenised.progress_apply(lambda word_list:pre.lemmatize_verbs(word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We also added spelling correction using the edit distance method as taught in the lecture however it took too long to process on the data therefore we had to remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature extraction\n",
    "word2index,word2count,index2word,n_words = pre.extract_features(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using gloVe pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets the all the words in gloVe that are a part of our word to index map\n",
    "def get_glove(path_to_glove,word2index_map):\n",
    "    embedding_weights = {}\n",
    "    count_all_words = 0\n",
    "    with open(path_to_glove,'r') as f:  \n",
    "        for line in f:\n",
    "            vals = line.split(' ')\n",
    "            word = str(vals[0])\n",
    "            if word in word2index_map:                \n",
    "                count_all_words += 1                                 \n",
    "                coefs = np.asarray(vals[1:],dtype='float32')\n",
    "                coefs /= np.linalg.norm(coefs)\n",
    "                embedding_weights[word] = coefs\n",
    "    mean = np.array(list(embedding_weights.values())).mean()\n",
    "    return embedding_weights, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all the embeddings in a dictionary and the mean of the embeddings\n",
    "word2embedding_dict, mean = get_glove(glove_word_embedding_path,word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sets the embeddings of the words that are found and the words that are not found are set to mean of the embeddings\n",
    "out_of_vocabulary = {}\n",
    "embedding_matrix = np.zeros((question_metadata.n_words,GLOVE_SIZE))\n",
    "for word,index in word2index.items():\n",
    "    try:        \n",
    "        word_embedding = word2embedding_dict[word]\n",
    "        embedding_matrix[index,:] = word_embedding\n",
    "    except:\n",
    "        out_of_vocabulary[word] = word2index[word]\n",
    "        embedding_matrix[index,:] = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size is 71928\n",
      "embedding found for 78.61055499944389 percentage of vocab\n"
     ]
    }
   ],
   "source": [
    "print(\"vocabulary size is {}\".format(n_words))\n",
    "print(\"embedding found for {} percentage of vocab\".format(((n_words-len(out_of_vocabulary))/n_words)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aleena/nlp/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#to obtain word's vector, tf.nn.embedding_lookup is used and embeddings are set to whatever we assign to the embedding placeholder\n",
    "with tf.variable_scope(\"embeddings\", reuse= tf.AUTO_REUSE):\n",
    "    \n",
    "    embeddings = tf.Variable(tf.constant(0.0, shape=[question_metadata.n_words,GLOVE_SIZE]),trainable=False)\n",
    "    embedding_init = embeddings.assign(embedding_placeholder)\n",
    "    embed = tf.nn.embedding_lookup(embeddings, _inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feeding LSTM to Dynamic RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-d72069b50d51>:4: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-20-d72069b50d51>:7: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/aleena/nlp/venv/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.variable_scope(\"lstm\", reuse= tf.AUTO_REUSE):\n",
    "    \n",
    "    lstm_cell = tf.nn.rnn_cell.LSTMCell(hidden_layer_size,forget_bias=1.0)\n",
    "    \n",
    "    #resolving the issue of adding noise as the form \"PAD\", by passing actual sequence length to tf.nn.dynamic_rnn() \n",
    "    output, states = tf.nn.dynamic_rnn(lstm_cell, embed, sequence_length = _seqlens,dtype=tf.float32)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings weights and biases\n",
    "with tf.variable_scope(\"linear_layer\", reuse= tf.AUTO_REUSE):\n",
    "    weights = {\n",
    "        'linear_layer': tf.Variable(tf.truncated_normal([hidden_layer_size,num_classes],mean=0,stddev=.01))\n",
    "    }\n",
    "\n",
    "    biases = {\n",
    "        'linear_layer': tf.Variable(tf.truncated_normal([num_classes],mean=0,stddev=.01))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-94757bca3ecf>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We use the last valid output vector and feed it to a linear layer and then calculate softmax and cross-entropy loss\n",
    "with tf.variable_scope(\"Optim\", reuse= tf.AUTO_REUSE):\n",
    "    final_output = tf.matmul(states[1],weights['linear_layer'])+ biases['linear_layer']\n",
    "    softmax = tf.nn.softmax_cross_entropy_with_logits(logits=final_output,labels=_labels)\n",
    "    cross_entropy = tf.reduce_mean(softmax)\n",
    "    tf.summary.scalar(\"cross_entropy\", cross_entropy)\n",
    "\n",
    "#optimization step \n",
    "    train_step = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cross_entropy)\n",
    "    correct_prediction = tf.equal(tf.argmax(_labels,1),tf.argmax(final_output,1))\n",
    "    accuracy = (tf.reduce_mean(tf.cast(correct_prediction,tf.float32)))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard Visualization & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy at 0: 59.37500\n",
      "Training Accuracy at 100: 42.18750\n",
      "Training Accuracy at 200: 71.09375\n",
      "Training Accuracy at 300: 71.09375\n",
      "Training Accuracy at 400: 75.00000\n",
      "WARNING:tensorflow:From /home/aleena/nlp/venv/lib/python3.6/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Training Accuracy at 500: 81.25000\n",
      "Training Accuracy at 600: 76.56250\n",
      "Training Accuracy at 700: 80.46875\n",
      "Training Accuracy at 800: 80.46875\n",
      "Training Accuracy at 900: 81.25000\n",
      "WARNING:tensorflow:From <ipython-input-23-1958a0470144>:34: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# Merge all summary ops\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    train_writer = tf.summary.FileWriter(LOG_DIR,graph=tf.get_default_graph())\n",
    "    saver = tf.train.Saver()\n",
    "    with open(os.path.join(LOG_DIR,'metadata.tsv'), \"w\") as metadata:\n",
    "        metadata.write('Name\\tClass\\n')\n",
    "        for k,v in index2word.items():\n",
    "            metadata.write('%s\\t%d\\n' % (v, k))\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = embeddings.name\n",
    "    # Link embedding to its metadata file\n",
    "    embedding.metadata_path = os.path.join(LOG_DIR,'metadata.tsv')\n",
    "    #for visualization of embeddings\n",
    "    projector.visualize_embeddings(train_writer, config)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #setting our embeddings to the embedding matrix created using gloVe\n",
    "    sess.run(embedding_init, feed_dict= {embedding_placeholder: embedding_matrix})\n",
    "    #training\n",
    "    for step in range(1000):\n",
    "        x_batch, y_batch, seqlen_batch = get_sentence_batch(batch_size,new_x_train,new_y_train,train_seqlens,question_metadata)\n",
    "        summary,_ = sess.run([merged, train_step],feed_dict={_inputs:x_batch,_labels:y_batch,_seqlens:seqlen_batch})\n",
    "        train_writer.add_summary(summary, step)\n",
    "        if step % 100 == 0:\n",
    "            #checkpointing the model\n",
    "            saver.save(sess, os.path.join(LOG_DIR, \"w2v_model.ckpt\"), step)\n",
    "            acc = sess.run(accuracy,feed_dict={_inputs:x_batch,_labels:y_batch,_seqlens:seqlen_batch})\n",
    "            print(\"Training Accuracy at %d: %.5f\" % (step,acc))\n",
    "            \n",
    "    # Normalize embeddings before using\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "    normalized_embeddings = embeddings / norm\n",
    "    normalized_embeddings_matrix = sess.run(normalized_embeddings)         \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on test data\n",
    "The model is loaded from the checkpoint and is run on the test data, the predictions are then saved to submission.csv and can be viewed there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aleena/nlp/venv/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./checkpointing/w2v_model.ckpt-900\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "saver.restore(sess, os.path.join(LOG_DIR, \"w2v_model.ckpt-900\"))\n",
    "all_preds = []\n",
    "for i in range(0, len(new_x_test), batch_size):\n",
    "    x_test_batch, seq_lens_test = get_test_batch(i,batch_size,new_x_test, test_seqlens, question_metadata_test)   \n",
    "    all_preds.extend(sess.run(tf.argmax(final_output,1), feed_dict={_inputs: x_test_batch, _seqlens: seq_lens_test}))\n",
    "    #print(all_preds)\n",
    "submit_df = pd.DataFrame({\"qid\": test_data[\"qid\"], \"prediction\": all_preds})\n",
    "submit_df.to_csv(\"submission.csv\", index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it out on your own!\n",
    "Added just for fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask a question to see if it's sincere or insincere\n"
     ]
    }
   ],
   "source": [
    "print(\"Ask a question to see if it's sincere or insincere\")\n",
    "your_question = input()\n",
    "question_list = []\n",
    "question_list.append(your_question)\n",
    "padded_sentence, sent_len = pre.make_input(your_question, time_steps)\n",
    "question_meta = get_question_metadata(question_list)\n",
    "q_test = get_test(padded_sentence, question_meta)  \n",
    "pred = sess.run(tf.argmax(final_output,1), feed_dict={_inputs:[q_test], _seqlens: [sent_len]})\n",
    "if pred[0] == 0:\n",
    "    print(\"That was a sincere question! Unfortunately, I don't have an answer.\")\n",
    "else:\n",
    "    print(\"Insincere! Don't try to fool me!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
